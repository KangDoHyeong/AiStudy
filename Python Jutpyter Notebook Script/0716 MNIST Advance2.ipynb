{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import random\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 Avg.cost = 0.1658\n",
      "Epoch:  0002 Avg.cost = 0.0491\n",
      "Epoch:  0003 Avg.cost = 0.0321\n",
      "Epoch:  0004 Avg.cost = 0.0238\n",
      "Epoch:  0005 Avg.cost = 0.0177\n",
      "Epoch:  0006 Avg.cost = 0.0139\n",
      "Epoch:  0007 Avg.cost = 0.0103\n",
      "Epoch:  0008 Avg.cost = 0.0080\n",
      "Epoch:  0009 Avg.cost = 0.0084\n",
      "Epoch:  0010 Avg.cost = 0.0066\n",
      "Epoch:  0011 Avg.cost = 0.0044\n",
      "Epoch:  0012 Avg.cost = 0.0060\n",
      "Epoch:  0013 Avg.cost = 0.0035\n",
      "Epoch:  0014 Avg.cost = 0.0048\n",
      "Epoch:  0015 Avg.cost = 0.0047\n",
      "정확도 : 0.9892\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None,28,28,1])\n",
    "Y = tf.placeholder(tf.float32,[None,10])\n",
    "is_training=tf.placeholder(tf.bool)\n",
    "\n",
    "L1 = tf.layers.conv2d(X,32,[3,3], activation = tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(L1, [2,2], [2,2])\n",
    "L1 = tf.layers.dropout(L1, 0.7, is_training)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1,64,[3,3], activation = tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(L2, [2,2], [2,2])\n",
    "L2 = tf.layers.dropout(L2, 0.7, is_training)\n",
    "\n",
    "L3 = tf.contrib.layers.flatten(L2)\n",
    "L3 = tf.layers.dense(L3, 256,activation=tf.nn.relu)\n",
    "L3 = tf.layers.dropout(L3, 0.5, is_training)\n",
    "\n",
    "model = tf.layers.dense(L3, 10, activation = None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size =100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "        _, cost_val = sess.run([optimizer,cost], feed_dict={X:batch_xs, Y: batch_ys, is_training:True})\n",
    "        total_cost += cost_val\n",
    "    print('Epoch: ', '%04d'%(epoch+1), 'Avg.cost =', '{:.4f}'.format(total_cost/total_batch))\n",
    "\n",
    "    \n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도 :', sess.run(accuracy, feed_dict={X:mnist.test.images.reshape(-1,28,28,1), Y:mnist.test.labels, is_training:False}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 Avg.cost = 0.2813\n",
      "Epoch:  0002 Avg.cost = 0.0806\n",
      "Epoch:  0003 Avg.cost = 0.0598\n",
      "Epoch:  0004 Avg.cost = 0.0446\n",
      "Epoch:  0005 Avg.cost = 0.0370\n",
      "Epoch:  0006 Avg.cost = 0.0301\n",
      "Epoch:  0007 Avg.cost = 0.0269\n",
      "Epoch:  0008 Avg.cost = 0.0221\n",
      "Epoch:  0009 Avg.cost = 0.0172\n",
      "Epoch:  0010 Avg.cost = 0.0160\n",
      "Epoch:  0011 Avg.cost = 0.0154\n",
      "Epoch:  0012 Avg.cost = 0.0131\n",
      "Epoch:  0013 Avg.cost = 0.0097\n",
      "Epoch:  0014 Avg.cost = 0.0126\n",
      "Epoch:  0015 Avg.cost = 0.0090\n",
      "Epoch:  0016 Avg.cost = 0.0072\n",
      "Epoch:  0017 Avg.cost = 0.0087\n",
      "Epoch:  0018 Avg.cost = 0.0071\n",
      "Epoch:  0019 Avg.cost = 0.0083\n",
      "Epoch:  0020 Avg.cost = 0.0064\n",
      "정확도 : 0.9866\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None,28,28,1])\n",
    "Y = tf.placeholder(tf.float32,[None,10])\n",
    "is_training=tf.placeholder(tf.bool)\n",
    "\n",
    "L1 = tf.layers.conv2d(X,32,[3,3], activation = tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(L1, [2,2], [2,2])\n",
    "L1 = tf.layers.dropout(L1, 0.7, is_training)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1,64,[3,3], activation = tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(L2, [2,2], [2,2])\n",
    "L2 = tf.layers.dropout(L2, 0.7, is_training)\n",
    "\n",
    "L3 = tf.layers.conv2d(L2,128,[3,3], activation = tf.nn.relu)\n",
    "L3 = tf.layers.max_pooling2d(L3, [2,2], [2,2])\n",
    "L3 = tf.layers.dropout(L3, 0.7, is_training)\n",
    "\n",
    "L4 = tf.contrib.layers.flatten(L3)\n",
    "L4 = tf.layers.dense(L4, 256, activation=tf.nn.relu)\n",
    "L4 = tf.layers.dropout(L4, 0.5, is_training)\n",
    "\n",
    "model = tf.layers.dense(L4, 10, activation = None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size =100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1,28,28,1)\n",
    "        _, cost_val = sess.run([optimizer,cost], feed_dict={X:batch_xs, Y: batch_ys, is_training:True})\n",
    "        total_cost += cost_val\n",
    "    print('Epoch: ', '%04d'%(epoch+1), 'Avg.cost =', '{:.4f}'.format(total_cost/total_batch))\n",
    "\n",
    "    \n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도 :', sess.run(accuracy, feed_dict={X:mnist.test.images.reshape(-1,28,28,1), Y:mnist.test.labels, is_training:False}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
